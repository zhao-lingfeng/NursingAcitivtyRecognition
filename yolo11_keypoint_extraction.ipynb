{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPoOt7LlNt00U8qjc0U0XtC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hcjR8p2I5Z1E","executionInfo":{"status":"ok","timestamp":1730738484369,"user_tz":-540,"elapsed":20462,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}},"outputId":"480d0fa5-a7bc-4d22-b7bc-8b7e87f4e37c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Configure necessary libraries"],"metadata":{"id":"-aqVYCOGK8Hj"}},{"cell_type":"code","source":["!pip install ultralytics\n","!pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CU7ebgI08oeT","executionInfo":{"status":"ok","timestamp":1730738503682,"user_tz":-540,"elapsed":14121,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}},"outputId":"ca9e57ee-0f3e-4374-9411-c2d8c2d16380"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.27-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.10-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.27-py3-none-any.whl (878 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.10-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.27 ultralytics-thop-2.0.10\n","Collecting mediapipe\n","  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n","Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n","Collecting protobuf<5,>=4.25.3 (from mediapipe)\n","  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: protobuf, sounddevice, mediapipe\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed mediapipe-0.10.18 protobuf-4.25.5 sounddevice-0.5.1\n"]}]},{"cell_type":"markdown","source":["# Setting the Path"],"metadata":{"id":"kbjOhSD-LMNq"}},{"cell_type":"code","source":["\"\"\"\n","# Already completed videos:\n","\n","Front_T1F01.mp4, Front_T1F02.mp4, Front_T2F01.mp4, Front_T2F02.mp4, Front_T3F01.mp4, Front_T3F02.mp4,\n","Front_T1N01.mp4, Front_T1N02.mp4, Front_T2N01.mp4, Front_T2N02.mp4, Front_T3N01.mp4, Front_T3N02.mp4,\n","Front_T2S01.mp4, Front_T2S02.mp4, Front_T3S01.mp4, Frent_T3S02.mp4.\n","\n","# Processed separately：\n","(Front_T1S01.mp4, Front_T1S02.mp4),\n","\"\"\"\n","\n","# 设置视频文件路径\n","VIDEO_PATH = '/content/drive/MyDrive/Random/Hiroshima/ABC2025/New_Data/Video/Front_T1S01.mp4'  # 视频路径\n","\n","# 设置保存路径\n","MARKED_VIDEO_PATH = '/content/drive/MyDrive/Random/Hiroshima/ABC2025/New_Data/Ann_Video/KeyPoint_Ann_video/Front_T1S01.mp4'  # 保存带标记视频的路径\n","BODY_KEYPOINTS_CSV_PATH = '/content/drive/MyDrive/Random/Hiroshima/ABC2025/New_Data/Body_KeyPoint_CSV/Front_T1S01.csv'  # 保存人体骨架数据的CSV路径"],"metadata":{"id":"JRVGSejX-ScI","executionInfo":{"status":"ok","timestamp":1730739009097,"user_tz":-540,"elapsed":475,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"lDQR4Yt-LXdW"}},{"cell_type":"code","source":["import cv2\n","import random\n","import pandas as pd\n","from ultralytics import YOLO\n","import matplotlib.pyplot as plt"],"metadata":{"id":"0RElOOySo4Je","executionInfo":{"status":"ok","timestamp":1730738891772,"user_tz":-540,"elapsed":449,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# 加载YOLO11模型\n","# model = YOLO('yolo11n-pose.pt')\n","model = YOLO('yolo11m-pose.pt')"],"metadata":{"id":"4UDFHATiTzM4","executionInfo":{"status":"ok","timestamp":1730738894645,"user_tz":-540,"elapsed":465,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 定义骨骼点的名称\n","keypoint_names = [\"nose\", \"right_eye\", \"left_eye\", \"right_ear\", \"left_ear\",\n","                  \"right_shoulder\", \"left_shoulder\", \"right_elbow\", \"left_elbow\",\n","                  \"right_wrist\", \"left_wrist\", \"right_hip\", \"left_hip\",\n","                  \"right_knee\", \"left_knee\", \"right_ankle\", \"left_ankle\"]"],"metadata":{"id":"gKkcPa8aT4Ut","executionInfo":{"status":"ok","timestamp":1730738897738,"user_tz":-540,"elapsed":581,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 定义骨架连接顺序\n","skeleton_map = [\n","    # 腿部\n","    {'srt_kpt_id': 15, 'dst_kpt_id': 13, 'color': (255, 182, 193), 'thickness': 2},  # 右脚踝到右膝\n","    {'srt_kpt_id': 13, 'dst_kpt_id': 11, 'color': (255, 182, 193), 'thickness': 2},  # 右膝到右臀\n","    {'srt_kpt_id': 16, 'dst_kpt_id': 14, 'color': (255, 182, 193), 'thickness': 2},  # 左脚踝到左膝\n","    {'srt_kpt_id': 14, 'dst_kpt_id': 12, 'color': (255, 182, 193), 'thickness': 2},  # 左膝到左臀\n","\n","    # 躯干\n","    {'srt_kpt_id': 11, 'dst_kpt_id': 12, 'color': (0, 255, 0), 'thickness': 2},       # 右臀到左臀\n","    {'srt_kpt_id': 5, 'dst_kpt_id': 11, 'color': (0, 255, 0), 'thickness': 2},        # 右肩到右臀\n","    {'srt_kpt_id': 6, 'dst_kpt_id': 12, 'color': (0, 255, 0), 'thickness': 2},        # 左肩到左臀\n","    {'srt_kpt_id': 5, 'dst_kpt_id': 6, 'color': (0, 255, 0), 'thickness': 2},         # 右肩到左肩\n","\n","    # 手臂\n","    {'srt_kpt_id': 5, 'dst_kpt_id': 7, 'color': (0, 0, 255), 'thickness': 2},         # 右肩到右肘\n","    {'srt_kpt_id': 6, 'dst_kpt_id': 8, 'color': (0, 0, 255), 'thickness': 2},         # 左肩到左肘\n","    {'srt_kpt_id': 7, 'dst_kpt_id': 9, 'color': (0, 0, 255), 'thickness': 2},         # 右肘到右腕\n","    {'srt_kpt_id': 8, 'dst_kpt_id': 10, 'color': (0, 0, 255), 'thickness': 2},        # 左肘到左腕\n","\n","    # 脸部\n","    {'srt_kpt_id': 1, 'dst_kpt_id': 2, 'color': (255, 165, 0), 'thickness': 2},       # 右眼到左眼\n","    {'srt_kpt_id': 0, 'dst_kpt_id': 1, 'color': (255, 165, 0), 'thickness': 2},       # 鼻到右眼\n","    {'srt_kpt_id': 0, 'dst_kpt_id': 2, 'color': (255, 165, 0), 'thickness': 2},       # 鼻到左眼\n","    {'srt_kpt_id': 1, 'dst_kpt_id': 3, 'color': (255, 165, 0), 'thickness': 2},       # 右眼到右耳\n","    {'srt_kpt_id': 2, 'dst_kpt_id': 4, 'color': (255, 165, 0), 'thickness': 2},       # 左眼到左耳\n","    {'srt_kpt_id': 3, 'dst_kpt_id': 5, 'color': (255, 165, 0), 'thickness': 2},       # 右耳到右肩\n","    {'srt_kpt_id': 4, 'dst_kpt_id': 6, 'color': (255, 165, 0), 'thickness': 2}        # 左耳到左肩\n","]"],"metadata":{"id":"WcPUJJY_UCdB","executionInfo":{"status":"ok","timestamp":1730738900154,"user_tz":-540,"elapsed":2,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# 定义连接绘制函数\n","def draw_skeleton(annotated_frame, keypoints, skeleton_map):\n","    for connection in skeleton_map:\n","        srt_kpt_id = connection['srt_kpt_id']\n","        dst_kpt_id = connection['dst_kpt_id']\n","        color = connection['color']\n","        thickness = connection['thickness']\n","\n","        # 获取起始和结束关键点的坐标\n","        x1, y1 = keypoints.get(f\"{keypoint_names[srt_kpt_id]}_x\", -1), keypoints.get(f\"{keypoint_names[srt_kpt_id]}_y\", -1)\n","        x2, y2 = keypoints.get(f\"{keypoint_names[dst_kpt_id]}_x\", -1), keypoints.get(f\"{keypoint_names[dst_kpt_id]}_y\", -1)\n","\n","        # 检查关键点是否有效 (非 -1 且不在 (0, 0) 位置)\n","        if (x1 != -1 and y1 != -1 and (x1, y1) != (0, 0)) and (x2 != -1 and y2 != -1 and (x2, y2) != (0, 0)):\n","            # 画出连接线\n","            cv2.line(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)"],"metadata":{"id":"NNTzASSfUJ6J","executionInfo":{"status":"ok","timestamp":1730738902632,"user_tz":-540,"elapsed":455,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# 可视化和保存函数（适用于没有背景干扰的情况）\n","def visualize_and_save(video_path, body_keypoints_csv_path, marked_video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_index = 0\n","    body_all_keypoints = []\n","\n","    # 设置视频输出\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    out = cv2.VideoWriter(marked_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        annotated_frame = frame.copy()\n","\n","        # YOLO 进行骨架点检测\n","        body_results = model(frame)\n","        for result in body_results:\n","            keypoints_with_conf = result.keypoints.data.tolist()  # 包含 x, y, conf\n","            if len(keypoints_with_conf) == 0:\n","                continue  # 如果没有检测到关键点，跳过\n","            body_keypoints_with_frame = {\"frame\": frame_index}\n","            for i, (x, y, conf) in enumerate(keypoints_with_conf[0]):\n","                if i < len(keypoint_names):\n","                    body_keypoints_with_frame[f\"{keypoint_names[i]}_x\"] = x\n","                    body_keypoints_with_frame[f\"{keypoint_names[i]}_y\"] = y\n","                    body_keypoints_with_frame[f\"{keypoint_names[i]}_conf\"] = conf\n","                    cv2.circle(annotated_frame, (int(x), int(y)), 3, (0, 255, 0), -1)\n","            body_all_keypoints.append(body_keypoints_with_frame)\n","\n","            # 绘制骨架连线\n","            draw_skeleton(annotated_frame, body_keypoints_with_frame, skeleton_map)\n","\n","        out.write(annotated_frame)\n","        frame_index += 1\n","\n","    # 保存人体骨架点数据到 CSV 文件\n","    body_df = pd.DataFrame(body_all_keypoints)\n","    body_df.to_csv(body_keypoints_csv_path, index=False)\n","\n","    cap.release()\n","    out.release()\n","    print(f\"标记视频已保存到 {marked_video_path}\")\n","    print(f\"人体骨架数据已保存到 {body_keypoints_csv_path}\")\n","\n","# 提取人体骨架点数据并保存\n","visualize_and_save(VIDEO_PATH, BODY_KEYPOINTS_CSV_PATH, MARKED_VIDEO_PATH)"],"metadata":{"id":"m_19wsun9E4E","executionInfo":{"status":"ok","timestamp":1730738904962,"user_tz":-540,"elapsed":462,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Dealing with background noise"],"metadata":{"id":"wGEiG6F5LcZA"}},{"cell_type":"code","source":["import cv2\n","from ultralytics import YOLO\n","from IPython.display import display, Image\n","import PIL.Image\n","import io"],"metadata":{"id":"iScir7beM3HE","executionInfo":{"status":"ok","timestamp":1730738945596,"user_tz":-540,"elapsed":458,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Only for videos:\n","\n","Front_T1S01.mp4, Front_T1S02.mp4.\n","\"\"\"\n","\n","\n","# 加载YOLO11模型\n","model = YOLO('yolo11m-pose.pt')\n","\n","# 设置边界框 (左, 上, 右, 下) - 1920x1080\n","bbox = (300, 0, 1920, 1080)\n","\n","def show_bbox(video_path, show_frames=1):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_index = 0\n","\n","    while cap.isOpened() and frame_index < show_frames:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        annotated_frame = frame.copy()\n","\n","        # 显示边界框\n","        cv2.rectangle(annotated_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)  # 绿色边界框用于展示\n","\n","        # 转换为JPG格式\n","        _, img_encoded = cv2.imencode('.jpg', annotated_frame)\n","        img_bytes = img_encoded.tobytes()\n","        img = PIL.Image.open(io.BytesIO(img_bytes))\n","\n","        # 显示图片\n","        display(img)\n","\n","        frame_index += 1\n","\n","    cap.release()\n","    print(f\"前 {show_frames} 帧已显示完毕\")\n","\n","# 显示前几帧带边界框的视频\n","show_bbox(VIDEO_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":899,"output_embedded_package_id":"14w0k9hSVopH7ORP3YWllxAMNWb3oUTmV"},"id":"M3QcStkTLwcD","executionInfo":{"status":"ok","timestamp":1730739033865,"user_tz":-540,"elapsed":17281,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}},"outputId":"323d02e7-fc32-44e0-f3ba-5cb9bf22d67b"},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# 定义骨骼点的名称\n","keypoint_names = [\"nose\", \"right_eye\", \"left_eye\", \"right_ear\", \"left_ear\",\n","                  \"right_shoulder\", \"left_shoulder\", \"right_elbow\", \"left_elbow\",\n","                  \"right_wrist\", \"left_wrist\", \"right_hip\", \"left_hip\",\n","                  \"right_knee\", \"left_knee\", \"right_ankle\", \"left_ankle\"]"],"metadata":{"id":"DYA8MAUdY9Ul","executionInfo":{"status":"ok","timestamp":1730739038145,"user_tz":-540,"elapsed":445,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# 定义骨架连接顺序\n","skeleton_map = [\n","    # 腿部\n","    {'srt_kpt_id': 15, 'dst_kpt_id': 13, 'color': (255, 182, 193), 'thickness': 2},  # 右脚踝到右膝\n","    {'srt_kpt_id': 13, 'dst_kpt_id': 11, 'color': (255, 182, 193), 'thickness': 2},  # 右膝到右臀\n","    {'srt_kpt_id': 16, 'dst_kpt_id': 14, 'color': (255, 182, 193), 'thickness': 2},  # 左脚踝到左膝\n","    {'srt_kpt_id': 14, 'dst_kpt_id': 12, 'color': (255, 182, 193), 'thickness': 2},  # 左膝到左臀\n","\n","    # 躯干\n","    {'srt_kpt_id': 11, 'dst_kpt_id': 12, 'color': (0, 255, 0), 'thickness': 2},       # 右臀到左臀\n","    {'srt_kpt_id': 5, 'dst_kpt_id': 11, 'color': (0, 255, 0), 'thickness': 2},        # 右肩到右臀\n","    {'srt_kpt_id': 6, 'dst_kpt_id': 12, 'color': (0, 255, 0), 'thickness': 2},        # 左肩到左臀\n","    {'srt_kpt_id': 5, 'dst_kpt_id': 6, 'color': (0, 255, 0), 'thickness': 2},         # 右肩到左肩\n","\n","    # 手臂\n","    {'srt_kpt_id': 5, 'dst_kpt_id': 7, 'color': (0, 0, 255), 'thickness': 2},         # 右肩到右肘\n","    {'srt_kpt_id': 6, 'dst_kpt_id': 8, 'color': (0, 0, 255), 'thickness': 2},         # 左肩到左肘\n","    {'srt_kpt_id': 7, 'dst_kpt_id': 9, 'color': (0, 0, 255), 'thickness': 2},         # 右肘到右腕\n","    {'srt_kpt_id': 8, 'dst_kpt_id': 10, 'color': (0, 0, 255), 'thickness': 2},        # 左肘到左腕\n","\n","    # 脸部\n","    {'srt_kpt_id': 1, 'dst_kpt_id': 2, 'color': (255, 165, 0), 'thickness': 2},       # 右眼到左眼\n","    {'srt_kpt_id': 0, 'dst_kpt_id': 1, 'color': (255, 165, 0), 'thickness': 2},       # 鼻到右眼\n","    {'srt_kpt_id': 0, 'dst_kpt_id': 2, 'color': (255, 165, 0), 'thickness': 2},       # 鼻到左眼\n","    {'srt_kpt_id': 1, 'dst_kpt_id': 3, 'color': (255, 165, 0), 'thickness': 2},       # 右眼到右耳\n","    {'srt_kpt_id': 2, 'dst_kpt_id': 4, 'color': (255, 165, 0), 'thickness': 2},       # 左眼到左耳\n","    {'srt_kpt_id': 3, 'dst_kpt_id': 5, 'color': (255, 165, 0), 'thickness': 2},       # 右耳到右肩\n","    {'srt_kpt_id': 4, 'dst_kpt_id': 6, 'color': (255, 165, 0), 'thickness': 2}        # 左耳到左肩\n","]"],"metadata":{"id":"npekBiuKY8UR","executionInfo":{"status":"ok","timestamp":1730739039197,"user_tz":-540,"elapsed":1,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# 加载YOLO11模型\n","model = YOLO('yolo11m-pose.pt')\n","\n","# 设置边界框 (左, 上, 右, 下) - 1920x1080\n","bbox = (300, 0, 1920, 1080)\n","\n","# 绘制骨架连接的函数\n","def draw_skeleton(annotated_frame, keypoints, skeleton_map):\n","    for connection in skeleton_map:\n","        srt_kpt_id = connection['srt_kpt_id']\n","        dst_kpt_id = connection['dst_kpt_id']\n","        color = connection['color']\n","        thickness = connection['thickness']\n","\n","        # 获取起始和结束关键点的坐标\n","        x1, y1 = keypoints.get(f\"{keypoint_names[srt_kpt_id]}_x\", -1), keypoints.get(f\"{keypoint_names[srt_kpt_id]}_y\", -1)\n","        x2, y2 = keypoints.get(f\"{keypoint_names[dst_kpt_id]}_x\", -1), keypoints.get(f\"{keypoint_names[dst_kpt_id]}_y\", -1)\n","\n","        # 检查关键点是否有效 (非 -1 且不在 (0, 0) 位置)\n","        if (x1 != -1 and y1 != -1 and (x1, y1) != (0, 0)) and (x2 != -1 and y2 != -1 and (x2, y2) != (0, 0)):\n","            # 画出连接线\n","            cv2.line(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)\n","\n","# 可视化和保存函数（适用于有背景干扰的情况）\n","def visualize_and_save_with_bbox(video_path, body_keypoints_csv_path, marked_video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_index = 0\n","    body_all_keypoints = []\n","\n","    # 设置视频输出\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    out = cv2.VideoWriter(marked_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # 裁剪出边界框内的区域\n","        cropped_frame = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n","        annotated_frame = frame.copy()\n","\n","        # YOLO 进行骨架点检测\n","        body_results = model(cropped_frame)\n","        for result in body_results:\n","            keypoints_with_conf = result.keypoints.data.tolist()  # 包含 x, y, conf\n","            if len(keypoints_with_conf) == 0:\n","                continue  # 如果没有检测到关键点，跳过\n","            body_keypoints_with_frame = {\"Frame\": frame_index}\n","            for i, (x, y, conf) in enumerate(keypoints_with_conf[0]):\n","                # 将关键点坐标转换回原始帧坐标\n","                x += bbox[0]\n","                y += bbox[1]\n","\n","                if i < len(keypoint_names):\n","                    body_keypoints_with_frame[f\"{keypoint_names[i]}_x\"] = x\n","                    body_keypoints_with_frame[f\"{keypoint_names[i]}_y\"] = y\n","                    body_keypoints_with_frame[f\"{keypoint_names[i]}_conf\"] = conf\n","                    cv2.circle(annotated_frame, (int(x), int(y)), 3, (0, 255, 0), -1)\n","            body_all_keypoints.append(body_keypoints_with_frame)\n","\n","            # 绘制骨架连线\n","            draw_skeleton(annotated_frame, body_keypoints_with_frame, skeleton_map)\n","\n","        out.write(annotated_frame)\n","        frame_index += 1\n","\n","    # 保存人体骨架点数据到 CSV 文件\n","    body_df = pd.DataFrame(body_all_keypoints)\n","    body_df.to_csv(body_keypoints_csv_path, index=False)\n","\n","    cap.release()\n","    out.release()\n","    print(f\"标记视频已保存到 {marked_video_path}\")\n","    print(f\"人体骨架数据已保存到 {body_keypoints_csv_path}\")\n","\n","# 提取人体骨架点数据并保存\n","visualize_and_save(VIDEO_PATH, BODY_KEYPOINTS_CSV_PATH, MARKED_VIDEO_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0IgCULVdNhnJ","executionInfo":{"status":"error","timestamp":1730741271544,"user_tz":-540,"elapsed":2230196,"user":{"displayName":"趙凌峰","userId":"00744292700377544523"}},"outputId":"b8f27130-b001-47d8-f03b-68bf64b32e5e"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 3.0ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.9ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.5ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.5ms\n","Speed: 2.5ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.5ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 3.0ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.7ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.6ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.0ms\n","Speed: 3.4ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.8ms\n","Speed: 3.5ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.2ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 3.0ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.1ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.3ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.3ms\n","Speed: 2.4ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.4ms\n","Speed: 3.5ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.4ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 3.0ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.5ms\n","Speed: 2.4ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.1ms\n","Speed: 3.3ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.6ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.9ms\n","Speed: 2.1ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.9ms\n","Speed: 2.1ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.7ms\n","Speed: 2.2ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.6ms\n","Speed: 2.4ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.6ms\n","Speed: 2.4ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.0ms\n","Speed: 3.3ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.7ms\n","Speed: 3.3ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.1ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.2ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.8ms\n","Speed: 3.4ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.3ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.4ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.3ms\n","Speed: 2.8ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.7ms\n","Speed: 2.5ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.5ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.6ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.2ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.1ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.9ms\n","Speed: 2.3ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.6ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.6ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.9ms\n","Speed: 3.5ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.5ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.8ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 2.2ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.3ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.6ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.4ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.1ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.7ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.4ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.2ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.2ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.9ms\n","Speed: 2.1ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.9ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.7ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.9ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.8ms\n","Speed: 2.4ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 3.5ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.5ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.6ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.7ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.5ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 3.0ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.1ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.7ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.8ms\n","Speed: 2.7ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.6ms\n","Speed: 3.4ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.7ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 20.9ms\n","Speed: 2.7ms preprocess, 20.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.6ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.1ms\n","Speed: 3.4ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.6ms\n","Speed: 3.3ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.4ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.4ms\n","Speed: 2.6ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.4ms\n","Speed: 2.9ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 2.6ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.7ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.8ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.5ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.4ms\n","Speed: 3.4ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.7ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.5ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 3.1ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.1ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.2ms\n","Speed: 3.4ms preprocess, 19.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 2.3ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.3ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.8ms\n","Speed: 2.8ms preprocess, 18.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.9ms\n","Speed: 2.5ms preprocess, 17.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.3ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.6ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.5ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.5ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.6ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 3.0ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.6ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.5ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.5ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.9ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.5ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 3.0ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.2ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.5ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 2.6ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.5ms\n","Speed: 3.5ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.3ms\n","Speed: 3.4ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.2ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.6ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.9ms\n","Speed: 2.3ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.6ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.7ms\n","Speed: 2.9ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.2ms\n","Speed: 3.3ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.9ms\n","Speed: 2.8ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.4ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 69.6ms\n","Speed: 3.4ms preprocess, 69.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.9ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 3.1ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.7ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 3.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.4ms\n","Speed: 2.7ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 3.2ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.8ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.6ms\n","Speed: 3.4ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 3.1ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 2.6ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.3ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.4ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.0ms\n","Speed: 3.4ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.1ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.9ms\n","Speed: 2.3ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.8ms\n","Speed: 2.3ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 3.2ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.5ms\n","Speed: 3.7ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.7ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.6ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.7ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.8ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 3.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.3ms\n","Speed: 2.7ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 3.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.6ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.9ms\n","Speed: 2.3ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.7ms\n","Speed: 3.4ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.4ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.1ms\n","Speed: 2.6ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.0ms\n","Speed: 3.4ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 26.5ms\n","Speed: 3.3ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.6ms\n","Speed: 3.5ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.5ms\n","Speed: 2.4ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.6ms\n","Speed: 2.5ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.8ms\n","Speed: 3.4ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.2ms\n","Speed: 2.3ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.7ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 2.3ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.5ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.1ms\n","Speed: 2.7ms preprocess, 19.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.4ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 2.2ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.6ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.8ms\n","Speed: 3.4ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.8ms\n","Speed: 2.3ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.9ms\n","Speed: 2.4ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 20.3ms\n","Speed: 3.7ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.5ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.9ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.1ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.9ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.4ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.5ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.6ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 3.5ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.5ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.5ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.3ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.6ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 3.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.9ms\n","Speed: 3.4ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.4ms\n","Speed: 3.4ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.5ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.7ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.7ms\n","Speed: 3.5ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.2ms\n","Speed: 3.5ms preprocess, 19.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.5ms\n","Speed: 3.4ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.1ms\n","Speed: 3.4ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.2ms preprocess, 15.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.2ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.6ms\n","Speed: 3.4ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.7ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.0ms\n","Speed: 2.6ms preprocess, 18.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.5ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.8ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.8ms\n","Speed: 3.4ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.7ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.8ms\n","Speed: 3.5ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.3ms\n","Speed: 3.4ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.1ms\n","Speed: 2.4ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 3.0ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.8ms\n","Speed: 2.3ms preprocess, 18.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.7ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.5ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.8ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.3ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 3.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.2ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.7ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.1ms\n","Speed: 3.4ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.6ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.8ms\n","Speed: 3.3ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.2ms\n","Speed: 2.3ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.3ms\n","Speed: 2.5ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.2ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.1ms\n","Speed: 2.2ms preprocess, 17.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.9ms\n","Speed: 3.4ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.8ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.9ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.7ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.7ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.7ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.0ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.7ms\n","Speed: 2.9ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.7ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.9ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.9ms\n","Speed: 3.3ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.2ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.3ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.1ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.6ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.8ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.9ms\n","Speed: 3.3ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 2.5ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.5ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.5ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.5ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.2ms\n","Speed: 2.5ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.3ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.9ms\n","Speed: 3.4ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.7ms\n","Speed: 3.4ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.9ms\n","Speed: 3.3ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.1ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 2.7ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.8ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.3ms\n","Speed: 3.5ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.5ms\n","Speed: 2.4ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.9ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.7ms\n","Speed: 2.6ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.9ms\n","Speed: 2.3ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.2ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.5ms\n","Speed: 3.3ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.7ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.6ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.7ms\n","Speed: 3.5ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.4ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.3ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 3.4ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.7ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.8ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.6ms\n","Speed: 2.4ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.3ms\n","Speed: 2.2ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 3.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.4ms\n","Speed: 2.9ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.8ms\n","Speed: 3.4ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 21.4ms\n","Speed: 2.2ms preprocess, 21.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.5ms\n","Speed: 3.2ms preprocess, 19.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.7ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 23.3ms\n","Speed: 3.3ms preprocess, 23.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.1ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.5ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.9ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.1ms\n","Speed: 3.4ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.6ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.1ms\n","Speed: 3.4ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.9ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.1ms\n","Speed: 2.4ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 23.5ms\n","Speed: 3.4ms preprocess, 23.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 20.2ms\n","Speed: 3.3ms preprocess, 20.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.3ms\n","Speed: 3.5ms preprocess, 19.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.9ms\n","Speed: 3.4ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.9ms\n","Speed: 2.7ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.5ms\n","Speed: 3.5ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.7ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.1ms\n","Speed: 3.5ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 23.5ms\n","Speed: 3.5ms preprocess, 23.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.5ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 3.0ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.9ms\n","Speed: 2.2ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.5ms\n","Speed: 3.1ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 3.4ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.3ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.2ms\n","Speed: 3.4ms preprocess, 19.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.5ms\n","Speed: 3.4ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.7ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.9ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.0ms\n","Speed: 3.4ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 2.1ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.9ms\n","Speed: 2.2ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.7ms\n","Speed: 2.5ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.4ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.7ms\n","Speed: 2.7ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.2ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.7ms\n","Speed: 2.4ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.8ms\n","Speed: 3.3ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.6ms\n","Speed: 2.7ms preprocess, 17.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.9ms\n","Speed: 2.4ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.4ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.1ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.1ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.4ms\n","Speed: 2.3ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.5ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.9ms\n","Speed: 2.8ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.9ms\n","Speed: 2.4ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.9ms\n","Speed: 3.4ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.5ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 3.0ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.1ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 3.1ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.1ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.2ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 3.1ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.0ms\n","Speed: 3.2ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.1ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.3ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.6ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.7ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.5ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.6ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.5ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.5ms\n","Speed: 2.5ms preprocess, 18.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.8ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.5ms\n","Speed: 2.9ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.9ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.7ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.4ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.7ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.9ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.1ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.1ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.5ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.8ms\n","Speed: 2.8ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.5ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.5ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.4ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.9ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.8ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.3ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.5ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.5ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.7ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.8ms\n","Speed: 3.5ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 3.0ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.0ms\n","Speed: 3.3ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.3ms\n","Speed: 3.4ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.2ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.8ms\n","Speed: 3.4ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.4ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.6ms\n","Speed: 3.5ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.6ms\n","Speed: 3.5ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.7ms\n","Speed: 2.3ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.7ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.3ms\n","Speed: 3.5ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.6ms\n","Speed: 2.4ms preprocess, 18.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.5ms\n","Speed: 2.4ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.8ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 21.0ms\n","Speed: 2.9ms preprocess, 21.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.6ms\n","Speed: 3.4ms preprocess, 19.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.2ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 3.1ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.3ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.7ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.6ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.4ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 3.3ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 3.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.6ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.1ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.6ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.3ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.4ms\n","Speed: 2.5ms preprocess, 19.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.9ms\n","Speed: 3.3ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.3ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 3.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.0ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.2ms\n","Speed: 3.4ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.2ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 3.2ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.5ms\n","Speed: 2.2ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.2ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.6ms\n","Speed: 3.3ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.5ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.2ms\n","Speed: 3.3ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.8ms\n","Speed: 2.4ms preprocess, 17.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.5ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.2ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 3.0ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.4ms\n","Speed: 2.5ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.3ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.1ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.1ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.8ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.8ms\n","Speed: 2.4ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.3ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.5ms\n","Speed: 3.0ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.2ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.2ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.1ms\n","Speed: 3.2ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.5ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.0ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.0ms\n","Speed: 2.1ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.1ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.1ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.6ms\n","Speed: 2.1ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.5ms\n","Speed: 3.4ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.7ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.0ms\n","Speed: 3.5ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.8ms\n","Speed: 3.4ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 3.1ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 20.7ms\n","Speed: 2.4ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.5ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 3.0ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.1ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.5ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.2ms\n","Speed: 3.3ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 3.4ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.2ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.1ms\n","Speed: 2.3ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.6ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 3.0ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.7ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.7ms\n","Speed: 2.3ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.5ms\n","Speed: 2.4ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.4ms\n","Speed: 2.8ms preprocess, 18.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 2.7ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.7ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 2.8ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.6ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.4ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.6ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 2.5ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.3ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.5ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 2.6ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.3ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.9ms\n","Speed: 3.4ms preprocess, 18.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.6ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.5ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 20.4ms\n","Speed: 2.6ms preprocess, 20.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.8ms\n","Speed: 2.3ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.9ms\n","Speed: 2.8ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 2.9ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.5ms\n","Speed: 3.4ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.6ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.4ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.7ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.3ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.9ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.2ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.6ms\n","Speed: 3.1ms preprocess, 18.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.9ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.7ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.6ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.6ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.7ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.0ms\n","Speed: 3.5ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.7ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.9ms\n","Speed: 3.4ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.6ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.7ms\n","Speed: 2.6ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.3ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.7ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.5ms\n","Speed: 3.5ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.7ms\n","Speed: 3.4ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.5ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.7ms\n","Speed: 3.4ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.1ms\n","Speed: 2.9ms preprocess, 19.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.3ms\n","Speed: 3.4ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.2ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.5ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.0ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.4ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.5ms\n","Speed: 3.4ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.6ms\n","Speed: 2.3ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.4ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.5ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 3.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.5ms\n","Speed: 2.5ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.2ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 3.5ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.9ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.9ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.3ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.3ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.3ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 3.0ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.5ms\n","Speed: 3.2ms preprocess, 19.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.0ms\n","Speed: 2.5ms preprocess, 19.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.5ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.4ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.2ms\n","Speed: 3.5ms preprocess, 18.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.2ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.3ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.6ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.5ms\n","Speed: 3.2ms preprocess, 19.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.6ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.8ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.1ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.5ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.5ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.6ms\n","Speed: 2.7ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.5ms\n","Speed: 2.5ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.2ms\n","Speed: 2.7ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.3ms\n","Speed: 3.2ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.9ms\n","Speed: 2.4ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.5ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.4ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 3.2ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.4ms\n","Speed: 2.6ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.2ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 2.4ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.5ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.4ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.6ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 3.0ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 3.1ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.7ms\n","Speed: 3.5ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.6ms\n","Speed: 3.5ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.2ms\n","Speed: 3.5ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.6ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.5ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.5ms\n","Speed: 3.4ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.2ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.7ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.6ms\n","Speed: 2.6ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.6ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.7ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.6ms\n","Speed: 2.6ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.6ms\n","Speed: 2.5ms preprocess, 17.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.6ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.6ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.5ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.6ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.4ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 3.0ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.7ms\n","Speed: 3.4ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.4ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.5ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.4ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.7ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.7ms\n","Speed: 3.1ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.6ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.4ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.3ms\n","Speed: 3.5ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.9ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.1ms\n","Speed: 2.4ms preprocess, 18.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.4ms\n","Speed: 2.5ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.2ms\n","Speed: 3.5ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.2ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 22.6ms\n","Speed: 3.4ms preprocess, 22.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.3ms\n","Speed: 2.7ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.9ms\n","Speed: 2.5ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.4ms\n","Speed: 2.4ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.6ms\n","Speed: 3.2ms preprocess, 19.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 3.3ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 3.4ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 3.4ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.9ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.4ms\n","Speed: 3.4ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.0ms\n","Speed: 3.3ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.6ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.2ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.9ms\n","Speed: 3.4ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.6ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.7ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 3.0ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.5ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.1ms\n","Speed: 2.5ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.4ms\n","Speed: 3.4ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.9ms\n","Speed: 3.3ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.3ms\n","Speed: 2.3ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.3ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 3.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 3.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.9ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.1ms\n","Speed: 2.5ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.4ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.5ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.7ms\n","Speed: 3.4ms preprocess, 18.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.3ms preprocess, 15.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.6ms\n","Speed: 3.4ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.2ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.1ms\n","Speed: 2.2ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.5ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.7ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.8ms\n","Speed: 3.4ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 20.3ms\n","Speed: 3.2ms preprocess, 20.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 20.3ms\n","Speed: 3.2ms preprocess, 20.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.8ms\n","Speed: 3.4ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.0ms\n","Speed: 3.4ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.4ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.4ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.6ms\n","Speed: 3.4ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.4ms\n","Speed: 3.4ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.3ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.7ms\n","Speed: 2.6ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.7ms\n","Speed: 2.5ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.1ms\n","Speed: 2.6ms preprocess, 19.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.5ms\n","Speed: 2.8ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.1ms\n","Speed: 3.4ms preprocess, 19.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 3.4ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.8ms\n","Speed: 2.3ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.8ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.5ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 3.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.1ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.2ms\n","Speed: 3.4ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.7ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.1ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.9ms\n","Speed: 3.4ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.1ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.5ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.8ms\n","Speed: 3.5ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.5ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.4ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.6ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.3ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.6ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.8ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.3ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 3.0ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 3.3ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.5ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.9ms\n","Speed: 2.7ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.3ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 3.2ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.9ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.3ms\n","Speed: 3.5ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.7ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.7ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.4ms\n","Speed: 2.2ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.5ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.6ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.5ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.3ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.3ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.7ms\n","Speed: 2.4ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.9ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 2.6ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.3ms\n","Speed: 2.5ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.6ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 3.1ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.2ms\n","Speed: 3.4ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.1ms\n","Speed: 3.4ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.4ms\n","Speed: 2.5ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.5ms\n","Speed: 3.0ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 2.3ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.6ms\n","Speed: 2.8ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.4ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.7ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.4ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.5ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.3ms\n","Speed: 3.3ms preprocess, 19.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.5ms\n","Speed: 3.3ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 2.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.6ms\n","Speed: 3.5ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 3.3ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.2ms\n","Speed: 3.4ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.9ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.2ms\n","Speed: 3.3ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.2ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.5ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.7ms\n","Speed: 2.1ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.6ms\n","Speed: 3.4ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.3ms\n","Speed: 3.5ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.9ms\n","Speed: 2.7ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.7ms\n","Speed: 2.2ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.6ms\n","Speed: 2.6ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 3.2ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.8ms\n","Speed: 3.5ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.6ms\n","Speed: 2.6ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.1ms\n","Speed: 2.3ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.2ms\n","Speed: 2.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.4ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.6ms\n","Speed: 3.4ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.2ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.0ms\n","Speed: 2.8ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.2ms\n","Speed: 3.5ms preprocess, 18.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.0ms\n","Speed: 2.7ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.6ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 18.7ms\n","Speed: 2.4ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 23.6ms\n","Speed: 2.5ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.7ms\n","Speed: 2.2ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.4ms\n","Speed: 3.4ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.3ms\n","Speed: 2.5ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 3.2ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.7ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.2ms\n","Speed: 3.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 16.7ms\n","Speed: 3.3ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 17.7ms\n","Speed: 2.2ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 2.2ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.8ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.5ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 14.5ms\n","Speed: 2.5ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.3ms\n","Speed: 3.0ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 15.4ms\n","Speed: 2.6ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 19.0ms\n","Speed: 2.8ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.5ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 20.1ms\n","Speed: 3.4ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.2ms\n","Speed: 2.8ms preprocess, 18.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.1ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.3ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.0ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 2.6ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.9ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.7ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.7ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.1ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.1ms\n","Speed: 3.4ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.3ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.5ms\n","Speed: 3.5ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.2ms\n","Speed: 2.3ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.3ms\n","Speed: 3.4ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.5ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.8ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.7ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.5ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.6ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.7ms\n","Speed: 2.3ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.9ms\n","Speed: 2.6ms preprocess, 18.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.6ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.0ms\n","Speed: 3.5ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.0ms\n","Speed: 3.5ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.3ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.5ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.6ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 3.0ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.4ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.6ms\n","Speed: 3.5ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 3.0ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.5ms\n","Speed: 2.4ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.4ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.5ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.6ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.7ms\n","Speed: 2.6ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.5ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.5ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.2ms\n","Speed: 3.4ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.6ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.8ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.4ms\n","Speed: 3.4ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.8ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 3.6ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.6ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.7ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.7ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 3.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.6ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.5ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.0ms\n","Speed: 2.3ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.9ms\n","Speed: 2.7ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.9ms\n","Speed: 3.1ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.5ms\n","Speed: 2.3ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.9ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.6ms\n","Speed: 3.4ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.6ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.5ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.1ms\n","Speed: 3.4ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.6ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.0ms\n","Speed: 3.4ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 3.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.6ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.9ms\n","Speed: 3.4ms preprocess, 17.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.6ms\n","Speed: 3.3ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.3ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.3ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.8ms\n","Speed: 2.4ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.2ms\n","Speed: 3.3ms preprocess, 18.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.4ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 2.6ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.6ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.4ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.9ms\n","Speed: 2.5ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.0ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.3ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.9ms\n","Speed: 2.3ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.3ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.7ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.2ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.5ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.7ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.9ms\n","Speed: 2.7ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.6ms\n","Speed: 3.5ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.2ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.7ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 3.0ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.1ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 3.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.4ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 2.8ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.6ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.2ms\n","Speed: 2.5ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.8ms\n","Speed: 3.4ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 3.0ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.4ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.0ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.2ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.4ms\n","Speed: 3.4ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.7ms\n","Speed: 2.2ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.5ms\n","Speed: 3.3ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.7ms\n","Speed: 3.4ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.6ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.5ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.3ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.0ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 3.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.3ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.6ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.3ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.7ms\n","Speed: 2.3ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.3ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.7ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.4ms\n","Speed: 2.3ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.8ms\n","Speed: 2.7ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.1ms\n","Speed: 2.3ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.9ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.9ms\n","Speed: 2.5ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.1ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.8ms\n","Speed: 2.3ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.4ms\n","Speed: 3.4ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.1ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 3.3ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.5ms\n","Speed: 3.5ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.4ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.1ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.1ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.1ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.0ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.7ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.2ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.9ms\n","Speed: 3.4ms preprocess, 18.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.6ms\n","Speed: 2.5ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.3ms\n","Speed: 2.6ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.2ms\n","Speed: 3.2ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.6ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.5ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.7ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.4ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 2.4ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.1ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.0ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 85.3ms\n","Speed: 2.3ms preprocess, 85.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.2ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.7ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.3ms\n","Speed: 2.3ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.5ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.2ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 2.3ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.5ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 2.5ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.2ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.0ms\n","Speed: 2.3ms preprocess, 18.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.4ms\n","Speed: 2.3ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.1ms\n","Speed: 2.4ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.5ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.9ms\n","Speed: 3.3ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.6ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.3ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 3.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.7ms\n","Speed: 3.3ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.4ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.9ms\n","Speed: 2.1ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.3ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.9ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.8ms\n","Speed: 3.2ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.5ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.1ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.9ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.7ms\n","Speed: 3.4ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.9ms\n","Speed: 2.4ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.9ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.8ms\n","Speed: 2.6ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 3.4ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.6ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.1ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 2.5ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.4ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.1ms\n","Speed: 2.2ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.9ms\n","Speed: 3.2ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.9ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 3.0ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.6ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.3ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.9ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.0ms\n","Speed: 3.4ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.3ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.4ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 2.4ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.3ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.6ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.5ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.5ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.5ms\n","Speed: 2.6ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.4ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.6ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.3ms\n","Speed: 2.7ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.8ms\n","Speed: 2.3ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.1ms\n","Speed: 3.4ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.0ms\n","Speed: 2.6ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.2ms\n","Speed: 3.4ms preprocess, 18.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.8ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.9ms\n","Speed: 2.2ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.8ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 3.3ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.4ms\n","Speed: 2.8ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.3ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.4ms\n","Speed: 2.3ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.0ms\n","Speed: 3.4ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.7ms\n","Speed: 2.5ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.5ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 19.3ms\n","Speed: 2.5ms preprocess, 19.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 20.8ms\n","Speed: 2.6ms preprocess, 20.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.5ms\n","Speed: 2.2ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.8ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.5ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.5ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.5ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.3ms\n","Speed: 3.3ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.9ms\n","Speed: 2.2ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.0ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.1ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.7ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.8ms\n","Speed: 2.2ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.4ms\n","Speed: 3.0ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.6ms\n","Speed: 3.3ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.7ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 20.4ms\n","Speed: 2.6ms preprocess, 20.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.3ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.6ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.4ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.1ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.2ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 3.2ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.1ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.3ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.6ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.4ms\n","Speed: 3.2ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.7ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.8ms\n","Speed: 2.6ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.9ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 16.1ms\n","Speed: 2.3ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.3ms\n","Speed: 2.4ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.3ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.1ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.1ms\n","Speed: 3.4ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.4ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.0ms\n","Speed: 2.6ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.2ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.9ms\n","Speed: 2.6ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.4ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.7ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.9ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.2ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.2ms\n","Speed: 2.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.6ms\n","Speed: 2.3ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.1ms\n","Speed: 2.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 2.4ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.5ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 17.2ms\n","Speed: 3.4ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.3ms\n","Speed: 2.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 18.8ms\n","Speed: 3.4ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.4ms\n","Speed: 2.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.9ms\n","Speed: 3.1ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 15.2ms\n","Speed: 2.3ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.1ms\n","Speed: 2.2ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 2.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.8ms\n","Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.6ms\n","Speed: 3.0ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.5ms\n","Speed: 2.2ms preprocess, 14.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.7ms\n","Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-77d3316c0830>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# 提取人体骨架点数据并保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mvisualize_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEO_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBODY_KEYPOINTS_CSV_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMARKED_VIDEO_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-f7e0763d5726>\u001b[0m in \u001b[0;36mvisualize_and_save\u001b[0;34m(video_path, body_keypoints_csv_path, marked_video_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# 提取人体骨架点数据并保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mvisualize_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEO_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBODY_KEYPOINTS_CSV_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMARKED_VIDEO_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-f7e0763d5726>\u001b[0m in \u001b[0;36mvisualize_and_save\u001b[0;34m(video_path, body_keypoints_csv_path, marked_video_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# 提取人体骨架点数据并保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mvisualize_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEO_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBODY_KEYPOINTS_CSV_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMARKED_VIDEO_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-f7e0763d5726>\u001b[0m in \u001b[0;36mvisualize_and_save\u001b[0;34m(video_path, body_keypoints_csv_path, marked_video_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# 提取人体骨架点数据并保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mvisualize_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEO_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBODY_KEYPOINTS_CSV_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMARKED_VIDEO_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-f7e0763d5726>\u001b[0m in \u001b[0;36mvisualize_and_save\u001b[0;34m(video_path, body_keypoints_csv_path, marked_video_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# YOLO 进行骨架点检测\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mbody_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mkeypoints_with_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeypoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 包含 x, y, conf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \"\"\"\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     def track(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"\"\"Streams real-time inference on camera feed and saves results to file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# Setup model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/logging/__init__.py\u001b[0m in \u001b[0;36minfo\u001b[0;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \"\"\"\n\u001b[1;32m   1476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/logging/__init__.py\u001b[0m in \u001b[0;36m_log\u001b[0;34m(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         record = self.makeRecord(self.name, level, fn, lno, msg, args,\n\u001b[1;32m   1623\u001b[0m                                  exc_info, func, extra, sinfo)\n\u001b[0;32m-> 1624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/logging/__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \"\"\"\n\u001b[1;32m   1633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisabled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallHandlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maddHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/logging/__init__.py\u001b[0m in \u001b[0;36mcallHandlers\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m   1694\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevelno\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1696\u001b[0;31m                     \u001b[0mhdlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1697\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m    \u001b[0;31m#break out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/logging/__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/logging/__init__.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;31m# issue 35046: merged two stream.writes into one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRecursionError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# See issue 36272\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/logging/__init__.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;31m# request flush on the background thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;31m# wait for flush to actually get through, if we can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# waiting across threads during import can cause deadlocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    618\u001b[0m                 )\n\u001b[1;32m    619\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def send_multipart(\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}